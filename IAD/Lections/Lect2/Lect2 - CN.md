формула гд
$$w^t = w^{t-1} - \eta \nabla Q(w^{t-1})$$ останавливаем процесс, если $$||w^t - w^{t-1}|| < \eps $$
Однако, в нейронках:
$$a(x) = FC_2(f(FC_1(x)))$$
где здесь веса?

>RELU - max(0, x), максимум из нуля и входа

>Веса в FC слоях и в f слоях (нелинейной функции)

функция потерь для каждого объекта:
![[Materials/Pasted image 20250911182131.jpeg]]
посчитаем производные для гд по параметрам
![[Materials/Pasted image 20250911182155.jpeg]]
разберем частный случай: квадратичная функция потерь
![[Materials/Pasted image 20250911182350.jpeg]]
сложная функция -> разбиваем
![[Materials/Pasted image 20250911182439.jpeg]]
теперь общий случай
![[Materials/Pasted image 20250911182716.jpeg]]
главная проблема - как считать производную выхода функции модели по параметру?

посмотрим на этот случай
![[Materials/Pasted image 20250911182904.jpeg]]

если "пошатать" единичку справа, то выход модели не изменится (там ноль в нейроне)

а если ноль вверху - то да, выход поменяется
![[Materials/Pasted image 20250911183003.jpeg]]

единичка слева справа тоже влияет на выход
![[Materials/Pasted image 20250911183031.jpeg]]

теперь надо научиться это все как-то считать в общем случае

![[Materials/Pasted image 20250911183111.jpeg]]

а чему равна производная формулы по p11?
Правильно - h1

чем больше h1(x), тем сильнее p11 влияет на a

идем дальше, производная по v11?
![[Materials/Pasted image 20250911183219.jpeg]]

Это можно сделать, но тут применяется правило дифференцирования сложных функций
![[Materials/Pasted image 20250911183325.jpeg]]

Тогда изменение v11 на ответ зависит сразу от двух связей

а производная по w11? 
Долго думаем, но в итоге вот так:
![[Materials/Pasted image 20250911183426.jpeg]]

2 слагаемых соответствуют двум путям - z1-h1-a и z1-h2-a

Действительно, это сумма произведений производных по путям

Страшно. Но эти формулы раскладываются на "кирпичики". Идя от конца к началу нужно брать производные по более поздним слоям. В этом случае можно организовать какой-то подсчёт производных.

backward pass - если мне нужно посчитать производные ради шага град спуска. Иду от конца к началу, потому что производные так считаются (зависят от поздних)

forward pass - для прогноза, ответа модели

обучение нейронки: forw, промежуточный ответ, backw, коррекция град спуском, forw, пром ответ, backw, коррекция, ...

***

MNIST - датасет из циферок

теорема цыбенко

что может выучить полносвязная нейронка?
![[Materials/Pasted image 20250911184937.jpeg]]

input_layer - 28х28 пикселей, вытянутые в вектор (на картинке неправильно, 28^2 = 784). Вот первый и второй полносвязные слои.
Каждый нейрон может детектировать заполненность конкретного набора пикселей.

Допустим, у нас есть единичка на картинке. Давай у нас веса будут такими, чтобы они назначали большие веса для набора закрашенных пикселей (паттерна)

Если будет столько же нейронов, сколько картинок, то каждому нейрону будет соответствовать какая-то картинка из обучающей выборке и на тестовой будет плохо (переобучение)

Проблема нашей архитектуры в том, что она не знает ничего про геометрию и трансформацию картинок.

> indactive bias - учет специфики данных 

784 входа, 1000 нейронов в полносвязном слое, 10 выходов
Почти миллион параметров и работает тоже плохо

Люди даже пытались на полносвязных сетях решить проблему, много параметров, максимально - 40% ответов

Полносвязные слои:
- очень много параметров
- легко переобучаются
- не учитывают специфику изображений
- один из лучших способов борьбы с переобучением - снижение числа параметров
Можно снизить связность слоёв!
### Операция свёртки

![[Materials/Pasted image 20250911190525.jpeg]]

Фильтр - обучаемый!

Смысл свёртки в следующем: фильтр находит свой паттерн в картинках, поэтому чем больше похожа матрица, тем более похожи будут выходы (2 и 2 на 1 и 2 рисунке)
![[Materials/Pasted image 20250911191203.jpeg]]
![[Materials/Pasted image 20250911191338.jpeg]]

максимум и там и там 2 => наличие паттерна и там и там есть (просто в разных местах)

Есть разные фильтры не в пределах МЛ (sobel horizontal kernel)

Формула свёртки следующая:
![[Materials/Pasted image 20250911191729.jpeg]]

im_out - результат свертки, im_in - вход, K - фильтр (с нечетным размером стороны = 2d+1 x 2d + 1), d - размер фильтра (не прямо, а косвенно через формулу, потому что в цикле внутри будет +-d), b - свободный коэф
![[Materials/Pasted image 20250911192136.jpeg]]

> в свёртке есть 2 важные фишки:
>- пиксель зависит только от маленького участка исходного изображения (local connectivity)
>- веса одни и те же для всех пикселей результирующего изображения (shared weights)


